---
title: "Build and deploy a stroke prediction model using R"
date: "`r Sys.Date()`"
output: html_document
author: "Brian Farrelly"
---

# About Data Analysis Report

This RMarkdown file contains the report of the data analysis done for the project on building and deploying a stroke prediction model in R. It contains analysis such as data exploration, summary statistics and building the prediction models. The final report was completed on `r date()`. 

**Data Description:**

According to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.

This data set is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relevant information about the patient.


# Task One: Import data and data preprocessing

## Load data and install packages


```{r}
# install needed libraries
install.packages("tidymodels")
install.packages("tidyverse")
install.packages("skimr")
install.packages("Metrics")
install.packages("glmnet")
install.packages("corrplot")
install.packages("randomForest")
install.packages("naivebayes")

```

```{r}
install.packages("naniar")

```
```{r}
install.packages("MLmetrics")

```
```{r}
install.packages("imbalance")

```



```{r}
# load libraries
library(tidyverse) # metapackage of all tidyverse packages
library(naniar) # handling missing data
library(skimr) # quick overview over the dataset
library(caret) # ML toolkit
library(MLmetrics) # F1 Score
library(imbalance) # algorithms to deal with imbalanced datasets
library(gridExtra) # display plots in grids
library(patchwork) # arrange plots side by side
```



```{r}
# Load the needed libraries
library(tidyverse)
library(tidymodels)
library(glmnet)
library(corrplot)
library(skimr)
library(randomForest)
library(naivebayes)
library(class)
library(caret)
library(e1071)
library(xgboost)
library(Metrics)
```


```{r}
library(DataExplorer)
```


```{r}
# set a seed for reproducible results
set.seed(88)
```


```{r}
# custom plot size function
fig <- function(width, heigth){
     options(repr.plot.width = width, repr.plot.height = heigth)
}
```

```{r}

## ggplot custom theme
theme_bigfont <- theme(plot.title = element_text(size=22),
                       axis.text.x= element_text(size=15),
                       axis.text.y= element_text(size=15), 
                       axis.title=element_text(size=18),
                       legend.text = element_text(size = 14))

```


```{r}
stroke_data <- read.csv("C:\\tools\\Rstudio\\projects\\stroke_data\\stroke.csv")
```




## Describe and explore the data

```{r}
str(stroke_data)
head(stroke_data)
plot_str(stroke_data)
plot_bar(stroke_data)
plot_bar(stroke_data, by="stroke")
```


```{r}
# summary of the data
summary(stroke_data)
```

```{r}

# check unique values of categorical values
cat("Gender:")
unique(stroke_data$gender)
cat("Married:")
unique(stroke_data$ever_married)
cat("Work type:")
unique(stroke_data$work_type)
cat("Residence type:")
unique(stroke_data$Residence_type)
cat("Smoking:")
unique(stroke_data$smoking_status)
```


```{r}

# how many "N/A" values are in my dataset per column?
miss_scan_count(data = stroke_data, search = list("N/A", "Unknown"))

```


```{r}

fig(15, 8)

stroke_data %>%
group_by(smoking_status) %>%
summarise(count = length(smoking_status)) %>%
mutate(smoking_status = factor(smoking_status)) %>%
ggplot(aes(x = fct_reorder(smoking_status, count), y = count, fill = factor(ifelse(smoking_status=="Unknown","Unknown","Known")))) +
geom_col() +
geom_text(aes(label = count, x = smoking_status, y = count), size = 6, hjust = 1.5) +
coord_flip() +
scale_fill_manual(values = c("Unknown" = "red", "Known" = "darkgrey")) +
labs(x = "smoking status") +
theme(legend.position = "none") +
theme_bigfont


```


```{r}

# replace the "N/A" in bmi
stroke_data_clean <- replace_with_na(data = stroke_data, replace = list(bmi = c("N/A"), smoking_status = c("Unknown"))) %>%
    # change bmi to numeric 
    mutate(bmi = as.numeric(bmi))

# check
summary(stroke_data_clean)
unique(stroke_data_clean$smoking_status)


```




```{r}

fig(15, 8)

# visualize the missing values
vis_miss(stroke_data_clean, cluster = TRUE) +
theme_bigfont

```



```{r}

fig(20, 30)

# create vector of column names with
cols <- stroke_data_clean %>% select(-id, -smoking_status) %>% names()
vis_plots_list <- list()

for (i in 1:length(cols)) {
    vis_plots_list[[i]] <- stroke_data_clean %>% arrange_at(cols[i]) %>% vis_miss() + labs(title = paste0("Ordered by ", cols[i]))
}

n <- length(vis_plots_list)
nCol <- floor(sqrt(n))
do.call("grid.arrange", c(vis_plots_list, ncol=nCol))


```






```{r}

fig(10, 8)

# check distribution of bmi
ggplot(stroke_data_clean, aes(x = bmi)) +
geom_histogram() +
labs(title = "Distribution of BMI") +
theme_bigfont

```




```{r}

fig(10,8)

# impute median and bind shadow to evaluate imputation
stroke_data_imp <- bind_shadow(stroke_data_clean) %>% 
impute_median_at(.vars = c("bmi")) %>%
add_label_shadow()

# Explore the median values in bmi in the imputed dataset
ggplot(stroke_data_imp, 
       aes(x = bmi_NA, y = bmi)) + 
geom_boxplot() +
labs(title = "Comparison, no-missing vs. imputed values for BMI") +
theme_bigfont

```

```{r}

stroke_data_imp <- impute_median_at(stroke_data_clean, .vars = c("bmi"))

```


```{r}

fig(16,8)

p1 <- ggplot(stroke_data_imp, 
       aes(x = smoking_status, fill = smoking_status)) + 
geom_bar() +
labs(title = "Before filling in NA values in smoking_status") +
theme(legend.position = "none") +
theme_bigfont

# fill imputation based on previous unique value in "smoking_status" column
after <- stroke_data_imp %>% 
fill(smoking_status)
# mode imputation which leads to worse performance of models:
#mutate(across(c(smoking_status)), replace(., is.na(.), "never smoked"))

# Explore the median values in bmi in the imputed dataset
p2 <- ggplot(after, 
       aes(x = smoking_status, fill = smoking_status)) + 
geom_bar() +
labs(title = "After filling in NA values in smoking_status") +
theme(legend.position = "none") +
theme_bigfont

p1 + p2

```

```{r}

stroke_data_imp2 <- stroke_data_imp %>%
fill(smoking_status) %>%
#mutate(across(c(smoking_status)), replace(., is.na(.), "never smoked")) %>%
mutate(across(c(hypertension, heart_disease), factor),
      across(where(is.character), as.factor),
      across(where(is.factor), as.numeric),
      stroke = factor(ifelse(stroke == 0, "no", "yes")))
```


```{r}

stroke_data_imp2 <- stroke_data_imp2 %>%
mutate(bmi = case_when(bmi < 18.5 ~ "underweight",
                      bmi >= 18.5 & bmi < 25 ~ "normal weight",
                      bmi >= 25 & bmi < 30 ~ "overweight",
                      bmi >= 30 ~ "obese"),
      bmi = factor(bmi, levels = c("underweight", "normal weight", "overweight", "obese"), order = TRUE))
      
```
      


```{r}

fig(10, 8)

# plot prop of people who had a stroke
stroke_data_imp2 %>%
select(stroke) %>%
ggplot(aes(x = stroke)) +
geom_bar() +
theme_bigfont

# count how many people had a stroke and the prop
stroke_data_imp2 %>%
group_by(stroke) %>%
summarize(n = n()) %>%
mutate(prop = round(n / sum(n), 2))

```



```{r}

# check imbalance ratio
imbalanceRatio(as.data.frame(stroke_data_imp2), classAttr = "stroke")

```
```{r}

stroke_test <- stroke_data_imp2 %>%
mutate(
    stroke = as.character(stroke),
    across(where(is.factor), as.numeric),
    stroke = factor(stroke)
)

stroke_oversampled <- oversample(as.data.frame(stroke_test), classAttr = "stroke", ratio = 1, method = "MWMOTE")

head(stroke_oversampled)

stroke_oversampled %>%
group_by(stroke) %>%
summarize(n = n()) %>%
mutate(prop = round(n / sum(n), 2))

```

```{r}

stroke_data_final <- stroke_oversampled %>% select(-id)

```


```{r}

# total number of observations
n_obs <- nrow(stroke_data_final)

# shuffle the dataset randomly
permuted_rows <- sample(n_obs)

# Randomly order data
stroke_shuffled <- stroke_data_final[permuted_rows,]

# Identify row to split on
split <- round(n_obs * 0.7)

# Create train
train <- stroke_shuffled[1:split,]

# Create test
test <- stroke_shuffled[(split + 1):nrow(stroke_shuffled),]

# check if train is really 70% of the original 
nrow(train) / nrow(stroke_data_final)

```


```{r}

# custom train control
myControl <- trainControl(
  method = "cv", 
  number = 10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE,
  verboseIter = TRUE
)

myGrid <- expand.grid(
    alpha = c(0,1),
    lambda = seq(0.00001, 1, length = 20)
)

set.seed(42)
glmnet_model <- train(
    stroke ~ .,
    train,
    method = "glmnet",
    tuneGrid = myGrid,
    trControl = myControl
)

```


      
```{r}

plot(glmnet_model)

max(glmnet_model[["results"]]$ROC)

```



```{r}

# check results of the glmnet model
glmnet_model[["results"]] %>% arrange(desc(ROC))

```



```{r}

mm_test <- test %>% select(-stroke)

glmnet_pred <- predict(glmnet_model, newdata = mm_test) 

confusionMatrix(glmnet_pred, factor(test[["stroke"]]), positive = "yes")

```

```{r}

# total number of observations in original dataset (before oversampling)
n_obs <- nrow(stroke_test)

# shuffle the dataset randomly
permuted_rows <- sample(n_obs)

# Randomly order data
stroke_shuffled <- stroke_test[permuted_rows,]

# Identify row to split on
split <- round(n_obs * 0.7)

# Create train
train_original <- stroke_shuffled[1:split,]

# Create test
test_original <- stroke_shuffled[(split + 1):nrow(stroke_shuffled),]

# check if train is really 70% of the original 
nrow(train_original) / nrow(stroke_test)

# test data of the original df without id and stroke column
test_original_no_stroke <- test_original %>% select(-id, -stroke)

```


```{r}

glmnet_pred_original <- predict(glmnet_model, newdata = test_original_no_stroke) 

confusionMatrix(glmnet_pred_original, factor(test_original[["stroke"]]), positive = "yes")

```




```{r}

cat("The GLMnet ridge regression models F1 Score on the original test set is: ", 
    round(F1_Score(factor(test_original[["stroke"]]), glmnet_pred_original, positive = "yes"), 4))

```


```{r}

rfGrid <- data.frame(
  .mtry = c(2,3,5,6),
  .splitrule = "gini",
  .min.node.size = 5
)

rfControl <- trainControl(
    method = "oob",
    number = 5,
    verboseIter = TRUE
)

rf_model <- train(
    stroke ~ .,
    train,
    method = "ranger",
    tuneLength = 3,
    tuneGrid = rfGrid,
    trControl = rfControl
)

```


```{r}

rf_model

```
    
    

```{r}

rf_pred <- predict(rf_model, newdata = mm_test) 

confusionMatrix(rf_pred, factor(test[["stroke"]]), positive = "yes")

```

```{r}

rf_pred_original <- predict(rf_model, newdata = test_original_no_stroke) 

confusionMatrix(rf_pred_original, factor(test_original[["stroke"]]), positive = "yes")

```


```{r}

cat("The random forest F1 Score on the original test set is: ", 
    round(F1_Score(factor(test_original[["stroke"]]), rf_pred_original, positive = "yes"), 4))
    
```
    
    
```{r}
    
xgbGrid <- expand.grid(
    nrounds = 3500,
    max_depth = 7,
    eta = 0.01,
    gamma = 0.01,
    colsample_bytree = 0.75,
    min_child_weight = 0,
    subsample = 0.5
)

xgbControl <- trainControl(
    method = "cv",
    number = 5
)

xgb_model <- train(
    stroke ~ .,
    train,
    method = "xgbTree",
    tuneLength = 3,
    tuneGrid = xgbGrid,
    trControl = xgbControl
)

```


```{r}

xgb_model

```    
    
    
```{r}
    
xbg_pred <- predict(xgb_model, newdata = mm_test) 

confusionMatrix(xbg_pred, factor(test[["stroke"]]), positive = "yes")

```

```{r}

xgb_pred_original <- predict(xgb_model, newdata = test_original_no_stroke) 

confusionMatrix(xgb_pred_original, factor(test_original[["stroke"]]), positive = "yes")

```




```{r}
    
    cat("The XGBoost classifiers F1 Score on the original test set is: ", 
    round(F1_Score(factor(test_original[["stroke"]]), xgb_pred_original, positive = "yes"), 4))
    
```
    
    